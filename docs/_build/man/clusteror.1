.\" Man page generated from reStructuredText.
.
.TH "CLUSTEROR" "1" "Dec 07, 2016" "0.0.post0.dev68+n166d2bb.dirty" "clusteror"
.SH NAME
clusteror \- clusteror 0.0.post0.dev68+n166d2bb.dirty
.
.nr rst2man-indent-level 0
.
.de1 rstReportMargin
\\$1 \\n[an-margin]
level \\n[rst2man-indent-level]
level margin: \\n[rst2man-indent\\n[rst2man-indent-level]]
-
\\n[rst2man-indent0]
\\n[rst2man-indent1]
\\n[rst2man-indent2]
..
.de1 INDENT
.\" .rstReportMargin pre:
. RS \\$1
. nr rst2man-indent\\n[rst2man-indent-level] \\n[an-margin]
. nr rst2man-indent-level +1
.\" .rstReportMargin post:
..
.de UNINDENT
. RE
.\" indent \\n[an-margin]
.\" old: \\n[rst2man-indent\\n[rst2man-indent-level]]
.nr rst2man-indent-level -1
.\" new: \\n[rst2man-indent\\n[rst2man-indent-level]]
.in \\n[rst2man-indent\\n[rst2man-indent-level]]u
..
.sp
This is the documentation of \fBclusteror\fP\&.
.SH CONTENTS
.SS License
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
MIT License

Copyright (c) 2016 Fei Zhan

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

.ft P
.fi
.UNINDENT
.UNINDENT
.SS Developers
.INDENT 0.0
.IP \(bu 2
Fei Zhan <\fI\%enfeizhan@gmail.com\fP>
.UNINDENT
.SS Modules
.SS clusteror package
.SS clusteror.core module
.sp
This module contains \fBClusteror\fP class capsulating raw data to discover
clusters from, the cleaned data for a clusteror to run on.
.sp
The clustering model encompasses two parts:
.INDENT 0.0
.IP 1. 3
Neural network:
Pre\-training (often encountered in Deep Learning context)
is implemented to achieve a goal that the neural network maps the input
data of higher dimension to a one dimensional representation. Ideally this
mapping is one\-to\-one.
A Denoising Autoencoder (DA) or Stacked Denoising Autoencoder (SDA) is
implemented for this purpose.
.IP 2. 3
One dimensional clustering model:
A separate model segments the samples against the one dimensional
representation. Two models are available in this class definition:
.INDENT 3.0
.INDENT 3.5
.INDENT 0.0
.IP \(bu 2
K\-Means
.IP \(bu 2
Valley model
.UNINDENT
.UNINDENT
.UNINDENT
.UNINDENT
.sp
The pivot idea here is given the neural network is a good one\-to\-one mapper
the separate clustering model on one dimensional representation is equivalent
to a clustering model on the original high dimensional data.
.sp
\fBNOTE:\fP
.INDENT 0.0
.INDENT 3.5
Valley model is explained in details in module \fBclusteror.utils\fP\&.
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B class clusteror.core.Clusteror(raw_data)
Bases: \fI\%object\fP
.sp
\fBClusteror\fP class can train neural networks \fIDA\fP or
\fISDA\fP, train taggers, or load saved models
from files.
.INDENT 7.0
.TP
.B Parameters
\fBraw_data\fP (\fIPandas DataFrame\fP) \-\- Dataframe read from data source. It can be original dataset without
any preprocessing or with a certain level of manipulation for
future analysis.
.UNINDENT
.INDENT 7.0
.TP
.B _raw_data
\fIPandas DataFrame\fP \-\- Stores the original dataset. It\(aqs the dataset that later
post\-clustering performance analysis will be based on.
.UNINDENT
.INDENT 7.0
.TP
.B _cleaned_data
\fIPandas DataFrame\fP \-\- Preprocessed data. Not necessarily has same number of columns with
\fB_raw_data\fP as a categorical column can derive multiple columns.
As the \fBtanh\fP function is used as activation function for symmetric
consideration. All columns should have values in range \fB[\-1, 1]\fP,
otherwise an \fBOutRangeError\fP will be raised.
.UNINDENT
.INDENT 7.0
.TP
.B _network
\fIstr\fP \-\- \fBda\fP for \fIDA\fP; \fBsda\fP for \fISDA\fP\&.
Facilating functions called with one or the other algorithm.
.UNINDENT
.INDENT 7.0
.TP
.B _da_dim_reducer
\fITheano function\fP \-\- Keeps the Theano function that is from trained DA model. Reduces
the dimension of the cleaned data down to one.
.UNINDENT
.INDENT 7.0
.TP
.B _sda_dim_reducer
\fITheano function\fP \-\- Keeps the Theano function that is from trained SDA model. Reduces
the dimension of the cleaned data down to one.
.UNINDENT
.INDENT 7.0
.TP
.B _one_dim_data
\fINumpy Array\fP \-\- The dimension reduced one dimensional data.
.UNINDENT
.INDENT 7.0
.TP
.B _valley
\fIPython function\fP \-\- Trained valley model tagging sample with their one dimensional
representation.
.UNINDENT
.INDENT 7.0
.TP
.B _kmeans
\fIScikit\-Learn K\-Means model\fP \-\- Trained K\-Means model tagging samples with their one dimensional
representation.
.UNINDENT
.INDENT 7.0
.TP
.B _tagger
\fIstr\fP \-\- Keeps records of which tagger implemented.
.UNINDENT
.INDENT 7.0
.TP
.B _field_importance
\fIList\fP \-\- Keeps the list of coefficiences that influence the clustering
emphasis.
.UNINDENT
.INDENT 7.0
.TP
.B add_cluster()
Tags each sample regarding their reduced one dimensional value. Adds
an extra column \fB\(aqcluster\(aq\fP to \fBraw_data\fP, seggesting a
zero\-based cluster ID.
.UNINDENT
.INDENT 7.0
.TP
.B cleaned_data
\fIPandas DataFrame\fP \-\- For assgining cleaned dataframe to \fB_cleaned_dat\fP\&.
.UNINDENT
.INDENT 7.0
.TP
.B da_dim_reducer
\fITheano function\fP \-\- Function that reduces dataset dimension. Attribute
\fB_network\fP is given \fBda\fP to designate the method of the
autoencoder as \fBDA\fP\&.
.UNINDENT
.INDENT 7.0
.TP
.B field_importance
\fIList\fP \-\- Significance that given to fields when training of neural
network is done. Fields with a large number will be given more
attention.
.sp
\fBNOTE:\fP
.INDENT 7.0
.INDENT 3.5
The importance is only meaningful relatively between fields. If no
values are specified, all fields are treated equally.
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B Parameters
\fBfield_importance\fP (\fIList or Dict, default None (List of Ones)\fP) \-\- .INDENT 7.0
.IP \(bu 2
If a list is designated, all fields should be assigned an
.UNINDENT
.sp
importance, viz, the length of the list should be equal to the
length of the features training the neural network.
.INDENT 7.0
.IP \(bu 2
It can also be given in a dict. In such a case, the fields can
.UNINDENT
.sp
be selectively given a value. Dict key is for field name and value
is for the importance. Fields not included will be initiated with
the default value one. A warning will be issued when a key is
not on the list of field names, mostly because of a typo.

.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B classmethod from_csv(filepath, **kwargs)
Class method for directly reading CSV file.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBfilepath\fP (\fI\%str\fP) \-\- Path to the CSV file
.IP \(bu 2
\fB**kwargs\fP (\fIkeyword arguments\fP) \-\- Other keyword arguments passed to \fBpandas.read_csv\fP
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B kmeans
\fIPython function\fP \-\- Trained on the dimension reduced one dimensional
data that segregates subjects into concentration of existence in a
subset of \fB[\-1, 1]\fP with K\-Means algorithm.  \fB_tagger\fP is
given \fBvalley\fP to facilitate follow\-up usages.
.UNINDENT
.INDENT 7.0
.TP
.B load_dim_reducer(filepath=\(aqdim_reducer.pk\(aq)
Loads saved dimension reducer. Need to first name the network type.
.INDENT 7.0
.TP
.B Parameters
\fBfilepath\fP (\fI\%str\fP) \-\- 
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B load_kmeans(filepath)
Loads a saved K\-Means tagger from a file.
.INDENT 7.0
.TP
.B filepath: str
File path to the file saving the K\-Means tagger.
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B load_valley(filepath)
Loads a saved valley tagger from a file. Create the valley function
from the saved parameters.
.INDENT 7.0
.TP
.B filepath: str
File path to the file saving the valley tagger.
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B one_dim_data
\fINumpy Array\fP \-\- Stores the output of neural network that has dimension
one.
.UNINDENT
.INDENT 7.0
.TP
.B raw_data
\fIPandas DataFrame\fP \-\- For assgining new values to \fB_raw_data\fP\&.
.UNINDENT
.INDENT 7.0
.TP
.B reduce_to_one_dim()
Reduces the dimension of input dataset to one before the tagging
in the next step.
.sp
Input of the Theano function is the cleaned data and output is a
one dimensional data stored in \fB_one_dim_data\fP\&.
.UNINDENT
.INDENT 7.0
.TP
.B save_dim_reducer(filepath=\(aqdim_reducer.pk\(aq, include_network=False)
Save dimension reducer from the neural network training.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBfilepath\fP (\fI\%str\fP) \-\- Filename to store the dimension reducer.
.IP \(bu 2
\fBinclude_network\fP (\fIboolean\fP) \-\- If true, prefix the filepath with the network type.
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B save_kmeans(filepath, include_taggername=False)
Saves K\-Means model to the named file path. Can add a prefix to
indicate this saves a K\-Means model.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBfilepath\fP (\fI\%str\fP) \-\- File path for saving the model.
.IP \(bu 2
\fBinclude_taggername\fP (\fIboolean, default False\fP) \-\- Include the \fBkmean_\fP prefix in filename if true.
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B save_valley(filepath, include_taggername=False)
Saves valley tagger.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBfilepath\fP (\fI\%str\fP) \-\- File path to save the tagger.
.IP \(bu 2
\fBinclude_taggername\fP (\fIboolean, default False\fP) \-\- Include the \fBvalley_\fP prefix in filename if true.
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B sda_dim_reducer
\fITheano function\fP \-\- Function that reduces dataset dimension. Attribute
\fB_network\fP is given \fBsda\fP to designate the method of the
autoencoder as \fBSDA\fP\&.
.UNINDENT
.INDENT 7.0
.TP
.B tagger
\fIstr\fP \-\- Name the tagger if necessary to do so, which will facilitate, e.g.
prefixing the filepath.
.UNINDENT
.INDENT 7.0
.TP
.B train_da_dim_reducer(field_importance=None, batch_size=50, corruption_level=0.3, learning_rate=0.002, min_epochs=200, patience=60, patience_increase=2, improvement_threshold=0.98, verbose=False)
Trains a \fBDA\fP neural network.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBfield_importance\fP (\fIList or Dict, default None (List of Ones)\fP) \-\- .INDENT 2.0
.IP \(bu 2
If a list is designated, all fields should be assigned an
.UNINDENT
.sp
importance, viz, the length of the list should be equal to the
length of the features training the neural network.
.INDENT 2.0
.IP \(bu 2
It can also be given in a dict. In such a case, the fields can
.UNINDENT
.sp
be selectively given a value. Dict key is for field name and value
is for the importance. Fields not included will be initiated with
the default value one. A warning will be issued when a key is
not on the list of field names, mostly because of a typo.

.IP \(bu 2
\fBbatch_size\fP (\fI\%int\fP) \-\- Size of each training batch. Necessary to derive the number
of batches.
.IP \(bu 2
\fBcorruption_level\fP (\fIfloat, between 0 and 1\fP) \-\- Dropout rate in reading input, typical pratice in deep learning
to avoid overfitting.
.IP \(bu 2
\fBlearning_rate\fP (\fI\%float\fP) \-\- Propagating step size for gredient descent algorithm.
.IP \(bu 2
\fBmin_epochs\fP (\fI\%int\fP) \-\- The mininum number of training epoch to run. It can be exceeded
depending on the setup of patience and ad\-hoc training progress.
.IP \(bu 2
\fBpatience\fP (\fI\%int\fP) \-\- True number of training epochs to run if larger than
\fBmin_epochs\fP\&. Note it is potentially increased during the
training if the cost is better than the expectation from
current cost.
.IP \(bu 2
\fBpatience_increase\fP (\fI\%int\fP) \-\- Coefficient used to increase patience against epochs that
have been run.
.IP \(bu 2
\fBimprovement_threshold\fP (\fIfloat, between 0 and 1\fP) \-\- Minimum improvement considered as substantial improvement, i.e.
new cost over existing lowest cost lower than this value.
.IP \(bu 2
\fBverbose\fP (\fIboolean, default False\fP) \-\- Prints out training at each epoch if true.
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B train_kmeans(n_clusters=10, **kwargs)
Trains K\-Means model on top of the one dimensional data derived from
dimension reducers.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBn_clusters\fP (\fI\%int\fP) \-\- The number of clusters required to start a K\-Means learning.
.IP \(bu 2
\fB**kwargs\fP (\fIkeyword arguments\fP) \-\- Any other keyword arguments passed on to Scikit\-Learn K\-Means
model.
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B train_sda_dim_reducer(field_importance=None, batch_size=50, hidden_layers_sizes=[20], corruption_levels=[0.3], learning_rate=0.002, min_epochs=200, patience=60, patience_increase=2, improvement_threshold=0.98, verbose=False)
Trains a \fBSDA\fP neural network.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBfield_importance\fP (\fIList or Dict, default None (List of Ones)\fP) \-\- .INDENT 2.0
.IP \(bu 2
If a list is designated, all fields should be assigned an
.UNINDENT
.sp
importance, viz, the length of the list should be equal to the
length of the features training the neural network.
.INDENT 2.0
.IP \(bu 2
It can also be given in a dict. In such a case, the fields can
.UNINDENT
.sp
be selectively given a value. Dict key is for field name and value
is for the importance. Fields not included will be initiated with
the default value one. A warning will be issued when a key is
not on the list of field names, mostly because of a typo.

.IP \(bu 2
\fBbatch_size\fP (\fI\%int\fP) \-\- Size of each training batch. Necessary to derive the number
of batches.
.IP \(bu 2
\fBhidden_layers_sizes\fP (\fIList of ints\fP) \-\- Number of neurons in the hidden layers (all but the input layer).
.IP \(bu 2
\fBcorruption_levels\fP (\fIList of floats, between 0 and 1\fP) \-\- Dropout rate in reading input, typical pratice in deep learning
to avoid overfitting.
.IP \(bu 2
\fBlearning_rate\fP (\fI\%float\fP) \-\- Propagating step size for gredient descent algorithm.
.IP \(bu 2
\fBmin_epochs\fP (\fI\%int\fP) \-\- The mininum number of training epoch to run. It can be exceeded
depending on the setup of patience and ad\-hoc training progress.
.IP \(bu 2
\fBpatience\fP (\fI\%int\fP) \-\- True number of training epochs to run if larger than
\fBmin_epochs\fP\&. Note it is potentially increased during the
training if the cost is better than the expectation from
current cost.
.IP \(bu 2
\fBpatience_increase\fP (\fI\%int\fP) \-\- Coefficient used to increase patience against epochs that
have been run.
.IP \(bu 2
\fBimprovement_threshold\fP (\fIfloat, between 0 and 1\fP) \-\- Minimum improvement considered as substantial improvement, i.e.
new cost over existing lowest cost lower than this value.
.IP \(bu 2
\fBverbose\fP (\fIboolean, default False\fP) \-\- Prints out training at each epoch if true.
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B train_valley(bins=100, contrast=0.3)
Trains the ability to cut the universe of samples into clusters based
how the dimension reduced dataset assembles in a histogram. Unlike
the K\-Means, no need to preset the number of clusters.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBbins\fP (\fI\%int\fP) \-\- Number of bins to aggregate the one dimensional data.
.IP \(bu 2
\fBcontrast\fP (\fIfloat, between 0 and 1\fP) \-\- Threshold used to define local minima and local maxima. Detailed
explanation in \fButils.find_local_extremes\fP\&.
.UNINDENT
.UNINDENT
.sp
\fBNOTE:\fP
.INDENT 7.0
.INDENT 3.5
When getting only one cluster, check the distribution of
\fBone_dim_data\fP\&. Likely the data points flock too close to each other.
Try increasing \fBbins\fP first. If not working, try different
neural networks with more or less layers with more or less neurons.
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B valley
\fIPython function\fP \-\- Trained on the dimension reduced one dimensional
data that segregates subjects into concentration of existence in a
subset of \fB[\-1, 1]\fP, by locating the "valley" in the distribution
landscape. \fB_tagger\fP is given \fBvalley\fP to facilitate
follow\-up usages.
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B exception clusteror.core.OutRangeError
Bases: \fI\%Exception\fP
.sp
Exceptions thrown as cleaned data go beyond range \fB[\-1, 1]\fP\&.
.UNINDENT
.SS clusteror.nn module
.sp
This module comprises of classes for neural networks.
.INDENT 0.0
.TP
.B class clusteror.nn.SdA(n_ins, hidden_layers_sizes, np_rs=None, theano_rs=None, field_importance=None, input_data=None)
Bases: \fI\%object\fP
.sp
Stacked Denoising Autoencoder (SDA) class.
.sp
A SdA model is obtained by stacking several DAs.
The hidden layer of the dA at layer \fIi\fP becomes the input of
the dA at layer \fIi+1\fP\&. The first layer dA gets as input the input of
the SdA, and the hidden layer of the last dA represents the output.
Note that after pretraining, the SdA is dealt with as a normal MLP,
the dAs are only used to initialize the weights.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBn_ins\fP (\fI\%int\fP) \-\- Input dimension.
.IP \(bu 2
\fBhidden_layers_sizes\fP (\fIlist of int\fP) \-\- Each int will be assgined to each hidden layer. Same number of hidden
layers will be created.
.IP \(bu 2
\fBnp_rs\fP (\fINumpy function\fP) \-\- Numpy random state.
.IP \(bu 2
\fBtheano_rs\fP (\fITheano function\fP) \-\- Theano random generator that gives symbolic random values.
.IP \(bu 2
\fBfield_importance\fP (\fIlist or Numpy array\fP) \-\- Put on each field when calculating the cost.  If not given,
all fields given equal weight ones.
.IP \(bu 2
\fBinput_data\fP (\fITheano symbolic variable\fP) \-\- Variable for input data.
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B theano_rs
\fITheano function\fP \-\- Theano random generator that gives symbolic random values.
.UNINDENT
.INDENT 7.0
.TP
.B field_importance
\fIlist or Numpy array\fP \-\- Put on each field when calculating the cost.  If not given,
all fields given equal weight ones.
.UNINDENT
.INDENT 7.0
.TP
.B W
\fITheano shared variable\fP \-\- Weight matrix. Dimension (n_visible, n_hidden).
.UNINDENT
.INDENT 7.0
.TP
.B W_prime
\fITheano shared variable\fP \-\- Transposed weight matrix. Dimension (n_hidden, n_visible).
.UNINDENT
.INDENT 7.0
.TP
.B bhid
\fITheano shared variable\fP \-\- Bias on output side. Dimension n_hidden.
.UNINDENT
.INDENT 7.0
.TP
.B bvis
\fITheano shared variable\fP \-\- Bias on input side. Dimension n_visible.
.UNINDENT
.INDENT 7.0
.TP
.B x
\fITheano symbolic variable\fP \-\- Used as input to build graph.
.UNINDENT
.INDENT 7.0
.TP
.B params
\fIlist\fP \-\- List packs neural network paramters.
.UNINDENT
.INDENT 7.0
.TP
.B dA_layers
\fIlist\fP \-\- List that keeps dA instances.
.UNINDENT
.INDENT 7.0
.TP
.B n_layers
\fIint\fP \-\- Number of hidden layers, len(dA_layers).
.UNINDENT
.INDENT 7.0
.TP
.B get_final_hidden_layer(input_data)
Computes the values of the last hidden layer.
.INDENT 7.0
.TP
.B Parameters
\fBinput_data\fP (\fITheano symbolic variable\fP) \-\- Data input to neural network.
.TP
.B Returns
A graph with output as the hidden layer values.
.TP
.B Return type
Theano graph
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B get_first_reconstructed_input(hidden)
Computes the reconstructed input given the values of the last
hidden layer.
.INDENT 7.0
.TP
.B Parameters
\fBhidden\fP (\fITheano symbolic variable\fP) \-\- Data input to neural network at the hidden layer side.
.TP
.B Returns
A graph with output as the reconstructed data at the visible side.
.TP
.B Return type
Theano graph
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B pretraining_functions(train_set, batch_size)
This function computes the cost and the updates for one trainng
step of the dA.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtrain_set\fP (\fITheano shared variable\fP) \-\- The complete training dataset.
.IP \(bu 2
\fBbatch_size\fP (\fI\%int\fP) \-\- Number of rows for each mini\-batch.
.UNINDENT
.TP
.B Returns
Theano functions that run one step training on each dA layers.
.TP
.B Return type
List
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B class clusteror.nn.dA(n_visible, n_hidden, np_rs=None, theano_rs=None, field_importance=None, initial_W=None, initial_bvis=None, initial_bhid=None, input_data=None)
Bases: \fI\%object\fP
.sp
Denoising Autoencoder (DA) class.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBn_visible\fP (\fI\%int\fP) \-\- Input dimension.
.IP \(bu 2
\fBn_hidden\fP (\fI\%int\fP) \-\- Output dimension.
.IP \(bu 2
\fBnp_rs\fP (\fINumpy function\fP) \-\- Numpy random state.
.IP \(bu 2
\fBtheano_rs\fP (\fITheano function\fP) \-\- Theano random generator that gives symbolic random values.
.IP \(bu 2
\fBfield_importance\fP (\fIlist or Numpy array\fP) \-\- Put on each field when calculating the cost.  If not given,
all fields given equal weight ones.
.IP \(bu 2
\fBinitial_W\fP (\fINumpy matrix\fP) \-\- Initial weight matrix. Dimension (n_visible, n_hidden).
.IP \(bu 2
\fBinitial_bvis\fP (\fINumpy array\fP) \-\- Initial bias on input side. Dimension n_visible.
.IP \(bu 2
\fBinitial_bhid\fP (\fINumpy arry\fP) \-\- Initial bias on output side. Dimension n_hidden.
.IP \(bu 2
\fBinput_data\fP (\fITheano symbolic variable\fP) \-\- Variable for input data.
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B theano_rs
\fITheano function\fP \-\- Theano random generator that gives symbolic random values.
.UNINDENT
.INDENT 7.0
.TP
.B field_importance
\fIlist or Numpy array\fP \-\- Put on each field when calculating the cost.  If not given,
all fields given equal weight ones.
.UNINDENT
.INDENT 7.0
.TP
.B W
\fITheano shared variable\fP \-\- Weight matrix. Dimension (n_visible, n_hidden).
.UNINDENT
.INDENT 7.0
.TP
.B W_prime
\fITheano shared variable\fP \-\- Transposed weight matrix. Dimension (n_hidden, n_visible).
.UNINDENT
.INDENT 7.0
.TP
.B bhid
\fITheano shared variable\fP \-\- Bias on output side. Dimension n_hidden.
.UNINDENT
.INDENT 7.0
.TP
.B bvis
\fITheano shared variable\fP \-\- Bias on input side. Dimension n_visible.
.UNINDENT
.INDENT 7.0
.TP
.B x
\fITheano symbolic variable\fP \-\- Used as input to build graph.
.UNINDENT
.INDENT 7.0
.TP
.B params
\fIlist\fP \-\- List packs neural network paramters.
.UNINDENT
.INDENT 7.0
.TP
.B get_corrupted_input(input_data, corruption_level)
Corrupts the input by multiplying input with an array of zeros and
ones that is generated by binomial trials.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBinput_data\fP (\fITheano symbolic variable\fP) \-\- Data input to neural network.
.IP \(bu 2
\fBcorruption_level\fP (\fIfloat or Theano symbolic variable\fP) \-\- Probability to corrupt a bit in the input data. Between 0 and 1.
.UNINDENT
.TP
.B Returns
A graph with output as the corrupted input.
.TP
.B Return type
Theano graph
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B get_cost_updates(corruption_level, learning_rate)
This function computes the cost and the updates for one trainng
step of the dA.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBcorruption_level\fP (\fIfloat or Theano symbolic variable\fP) \-\- Probability to corrupt a bit in the input data. Between 0 and 1.
.IP \(bu 2
\fBlearning_rate\fP (\fIfloat or Theano symbolic variable\fP) \-\- Step size for Gradient Descent algorithm.
.UNINDENT
.TP
.B Returns
.INDENT 7.0
.IP \(bu 2
\fBcost\fP (\fITheano graph\fP) \-\- A graph with output as the cost.
.IP \(bu 2
\fBupdates\fP (\fIList of tuples\fP) \-\- Instructions of how to update parameters. Used in training stage
to update parameters.
.UNINDENT

.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B get_hidden_values(input_data)
Computes the values of the hidden layer.
.INDENT 7.0
.TP
.B Parameters
\fBinput_data\fP (\fITheano symbolic variable\fP) \-\- Data input to neural network.
.TP
.B Returns
A graph with output as the hidden layer values.
.TP
.B Return type
Theano graph
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B get_reconstructed_input(hidden)
Computes the reconstructed input given the values of the
hidden layer.
.INDENT 7.0
.TP
.B Parameters
\fBhidden\fP (\fITheano symbolic variable\fP) \-\- Data input to neural network at the hidden layer side.
.TP
.B Returns
A graph with output as the reconstructed data at the visible side.
.TP
.B Return type
Theano graph
.UNINDENT
.UNINDENT
.UNINDENT
.SS clusteror.plot module
.sp
Plotting tools relevant for illustrating and comparing clustering results
can be found in this module.
.INDENT 0.0
.TP
.B clusteror.plot.group_occurance_plot(one_dim_data, cat_label, labels, group_label, colors=None, figsize=(10, 6), bbox_to_anchor=(1.01, 1), loc=2, grid=True, show=True, filepath=None, **kwargs)
Plot the distribution of a one dimensional \fBordinal or categorical\fP data
in a bar chart. This tool is useful to check the clustering impact in this
one\-dimensional sub\-space.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBone_dim_data\fP (\fIlist, Pandas Series, Numpy Array, or any iterable\fP) \-\- A sequence of data. Each element if for an instance.
.IP \(bu 2
\fBcat_label\fP (\fI\%str\fP) \-\- Field name will be used for the one dimensional data.
.IP \(bu 2
\fBlabels\fP (\fIlist, Pandas Series, Numpy Array, or any iterable\fP) \-\- The segment label for each sample in one_dim_data.
.IP \(bu 2
\fBgroup_label\fP (\fI\%str\fP) \-\- Field name will be used for the cluster ID.
.IP \(bu 2
\fBcolors\fP (\fIlist, default None\fP) \-\- Colours for each category existing in this one dimensional data.
Default colour scheme used if not supplied.
.IP \(bu 2
\fBfigsize\fP (\fI\%tuple\fP) \-\- Figure size (width, height).
.IP \(bu 2
\fBbbox_to_anchor\fP (\fI\%tuple\fP) \-\- Instruction to placing the legend box relative to the axes. Details
refer to \fBMatplotlib\fP document.
.IP \(bu 2
\fBloc\fP (\fI\%int\fP) \-\- The corner of the legend box to anchor. Details refer to \fBMatplotlib\fP
document.
.IP \(bu 2
\fBgrid\fP (\fIboolean, default True\fP) \-\- Show grid.
.IP \(bu 2
\fBshow\fP (\fIboolean, default True\fP) \-\- Show figure in pop\-up windows if true. Save to files if False.
.IP \(bu 2
\fBfilepath\fP (\fI\%str\fP) \-\- File name to saving the plot. Must be assigned a valid filepath if
\fBshow\fP is False.
.IP \(bu 2
\fB**kwargs\fP (\fIkeyword arguments\fP) \-\- Other keyword arguemnts passed on to \fBmatplotlib.pyplot.scatter\fP\&.
.UNINDENT
.UNINDENT
.sp
\fBNOTE:\fP
.INDENT 7.0
.INDENT 3.5
Instances in a same cluster does not necessarily assemble together in
all one dimensional sub\-spaces. There can be possibly no clustering
capaility for certain features. Additionally certain features play a
secondary role in clustering as having less importance in
\fBfield_importance\fP in \fBclusteror\fP module.
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B clusteror.plot.hist_plot_one_dim_group_data(one_dim_data, labels, bins=11, colors=None, figsize=(10, 6), xlabel=\(aqDimension Reduced Data\(aq, ylabel=\(aqOccurance\(aq, bbox_to_anchor=(1.01, 1), loc=2, grid=True, show=True, filepath=None, **kwargs)
Plot the distribution of a one dimensional numerical data in a histogram.
This tool is useful to check the clustering impact in this one\-dimensional
sub\-space.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBone_dim_data\fP (\fIlist, Pandas Series, Numpy Array, or any iterable\fP) \-\- A sequence of data. Each element if for an instance.
.IP \(bu 2
\fBlabels\fP (\fIlist, Pandas Series, Numpy Array, or any iterable\fP) \-\- The segment label for each sample in \fBone_dim_data\fP\&.
.IP \(bu 2
\fBbins\fP (\fIint or iterable\fP) \-\- If an integer, bins \- 1 bins created or a list of the delimiters.
.IP \(bu 2
\fBcolors\fP (\fIlist, default None\fP) \-\- Colours for each group. Use equally distanced colours on colour map
if not supplied.
.IP \(bu 2
\fBfigsize\fP (\fI\%tuple\fP) \-\- Figure size (width, height).
.IP \(bu 2
\fBxlabel\fP (\fI\%str\fP) \-\- Plot xlabel.
.IP \(bu 2
\fBylabel\fP (\fI\%str\fP) \-\- Plot ylabel.
.IP \(bu 2
\fBbbox_to_anchor\fP (\fI\%tuple\fP) \-\- Instruction to placing the legend box relative to the axes. Details
refer to \fBMatplotlib\fP document.
.IP \(bu 2
\fBloc\fP (\fI\%int\fP) \-\- The corner of the legend box to anchor. Details refer to \fBMatplotlib\fP
document.
.IP \(bu 2
\fBgrid\fP (\fIboolean, default True\fP) \-\- Show grid.
.IP \(bu 2
\fBshow\fP (\fIboolean, default True\fP) \-\- Show figure in pop\-up windows if true. Save to files if False.
.IP \(bu 2
\fBfilepath\fP (\fI\%str\fP) \-\- File name to saving the plot. Must be assigned a valid filepath if
\fBshow\fP is False.
.IP \(bu 2
\fB**kwargs\fP (\fIkeyword arguments\fP) \-\- Other keyword arguemnts passed on to \fBmatplotlib.pyplot.scatter\fP\&.
.UNINDENT
.UNINDENT
.sp
\fBNOTE:\fP
.INDENT 7.0
.INDENT 3.5
Instances in a same cluster does not necessarily assemble together in
all one dimensional sub\-spaces. There can be possibly no clustering
capaility for certain features. Additionally certain features play a
secondary role in clustering as having less importance in
\fBfield_importance\fP in \fBclusteror\fP module.
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B clusteror.plot.scatter_plot_two_dim_group_data(two_dim_data, labels, markers=None, colors=None, figsize=(10, 6), xlim=None, ylim=None, alpha=0.8, bbox_to_anchor=(1.01, 1), loc=2, grid=True, show=True, filepath=None, **kwargs)
Plot the distribution of a two dimensional data against clustering groups
in a scatter plot.
.sp
A point represents an instance in the dataset. Points in a same cluster
are painted with a same colour.
.sp
This tool is useful to check the clustering impact in this two\-dimensional
sub\-space.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtwo_dim_data\fP (\fIPandas DataFrame\fP) \-\- A dataframe with two columns. The first column goes to the x\-axis,
and the second column goes to the y\-axis.
.IP \(bu 2
\fBlabels\fP (\fIlist, Pandas Series, Numpy Array, or any iterable\fP) \-\- The segment label for each sample in \fBtwo_dim_data\fP\&.
.IP \(bu 2
\fBmarkers\fP (\fI\%list\fP) \-\- Marker names for each group.
.IP \(bu 2
\fBbbox_to_anchor\fP (\fI\%tuple\fP) \-\- Instruction to placing the legend box relative to the axes. Details
refer to \fBMatplotlib\fP document.
.IP \(bu 2
\fBcolors\fP (\fIlist, default None\fP) \-\- Colours for each group. Use equally distanced colours on colour map
if not supplied.
.IP \(bu 2
\fBfigsize\fP (\fI\%tuple\fP) \-\- Figure size (width, height).
.IP \(bu 2
\fBxlim\fP (\fI\%tuple\fP) \-\- X\-axis limits.
.IP \(bu 2
\fBylim\fP (\fI\%tuple\fP) \-\- Y\-axis limits.
.IP \(bu 2
\fBalpha\fP (\fIfloat, between 0 and 1\fP) \-\- Marker transparency. From 0 to 1: from transparent to opaque.
.IP \(bu 2
\fBloc\fP (\fI\%int\fP) \-\- The corner of the legend box to anchor. Details refer to \fBMatplotlib\fP
document.
.IP \(bu 2
\fBgrid\fP (\fIboolean, default True\fP) \-\- Show grid.
.IP \(bu 2
\fBshow\fP (\fIboolean, default True\fP) \-\- Show figure in pop\-up windows if true. Save to files if False.
.IP \(bu 2
\fBfilepath\fP (\fI\%str\fP) \-\- File name to saving the plot. Must be assigned a valid filepath if
\fBshow\fP is False.
.IP \(bu 2
\fB**kwargs\fP (\fIkeyword arguments\fP) \-\- Other keyword arguemnts passed on to \fBmatplotlib.pyplot.scatter\fP\&.
.UNINDENT
.UNINDENT
.sp
\fBNOTE:\fP
.INDENT 7.0
.INDENT 3.5
Instances in a same cluster does not necessarily assemble together in
all two dimensional sub\-spaces. There can be possibly no clustering
capaility for certain features. Additionally certain features play a
secondary role in clustering as having less importance in
\fBfield_importance\fP in \fBclusteror\fP module.
.UNINDENT
.UNINDENT
.UNINDENT
.SS clusteror.settings module
.SS clusteror.utils module
.sp
This module works as a transient store of useful functions. New standalone
functions will be first placed here. As they grow in number and can be
consolidated into an independent class, module, or even a new package.
.INDENT 0.0
.TP
.B clusteror.utils.find_local_extremes(series, contrast)
Finds local minima and maxima according to \fBcontrast\fP\&. In theory,
they can be determined by first derivative and second derivative. The
result derived this way is of no value in dealing with a very noisy,
zig\-zag data as too many local extremes would be found for any turn\-around.
The method presented here compares the point currently looked at and the
opposite potential extreme that is updated as scanning through the
data sequence. For instance, a potential maximum is 10, then a data point
of value smaller than 10 / (1 + contrast) is written down as a local
minimum.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBseries\fP (\fIPandas Series\fP) \-\- One dimenional data to find local extremes in.
.IP \(bu 2
\fBcontrast\fP (\fI\%float\fP) \-\- A value between 0 and 1 as a threshold between minimum and maximum.
.UNINDENT
.TP
.B Returns
.INDENT 7.0
.IP \(bu 2
\fBlocal_min_inds\fP (\fIlist\fP) \-\- List of indices for local minima.
.IP \(bu 2
\fBlocal_mins\fP (\fIlist\fP) \-\- List of minimum values.
.IP \(bu 2
\fBlocal_max_inds\fP (\fIlist\fP) \-\- List of indices for local maxima.
.IP \(bu 2
\fBlocal_maxs\fP (\fIlist\fP) \-\- List of maximum values.
.UNINDENT

.UNINDENT
.UNINDENT
.SS tests package
.SS Submodules
.SS tests.conftest module
.sp
Dummy conftest.py for clusteror.
.sp
If you don\(aqt know what this is for, just leave it empty.
Read more about conftest.py under:
\fI\%https://pytest.org/latest/plugins.html\fP
.SS tests.example_iris module
.SS tests.example_tips module
.SS tests.test_clusteror module
.INDENT 0.0
.TP
.B class tests.test_clusteror.TestDA(methodName=\(aqrunTest\(aq)
Bases: \fBunittest.case.TestCase\fP
.INDENT 7.0
.TP
.B setUp()
.UNINDENT
.INDENT 7.0
.TP
.B test_dA_conrrupted_input()
.UNINDENT
.INDENT 7.0
.TP
.B test_dA_cost()
.UNINDENT
.INDENT 7.0
.TP
.B test_dA_hidden_values()
.UNINDENT
.INDENT 7.0
.TP
.B test_dA_reconstructed_input()
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B class tests.test_clusteror.TestSdA(methodName=\(aqrunTest\(aq)
Bases: \fBunittest.case.TestCase\fP
.INDENT 7.0
.TP
.B setUp()
.UNINDENT
.INDENT 7.0
.TP
.B test_SdA_final_hidden_layer()
.UNINDENT
.INDENT 7.0
.TP
.B test_SdA_first_reconstructed_layer()
.UNINDENT
.INDENT 7.0
.TP
.B test_SdA_pretraining_functions()
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B tests.test_clusteror.tanh_cross_entropy(field_importance, dat_in, dat_rec)
.UNINDENT
.SS tests.test_skeleton module
.INDENT 0.0
.TP
.B tests.test_skeleton.test_fib()
.UNINDENT
.SS Module contents
.SS versioneer module
.sp
The Versioneer \- like a rocketeer, but for versions.
.SS The Versioneer
.INDENT 0.0
.IP \(bu 2
like a rocketeer, but for versions!
.IP \(bu 2
\fI\%https://github.com/warner/python\-versioneer\fP
.IP \(bu 2
Brian Warner
.IP \(bu 2
License: Public Domain
.IP \(bu 2
Compatible With: python2.6, 2.7, 3.2, 3.3, 3.4, 3.5, and pypy
.IP \(bu 2
[![Latest Version]
.UNINDENT
.sp
(\fI\%https://pypip.in/version/versioneer/badge.svg?style=flat\fP)
](\fI\%https://pypi.python.org/pypi/versioneer/\fP)
* [![Build Status]
(\fI\%https://travis\-ci.org/warner/python\-versioneer.png?branch=master\fP)
](\fI\%https://travis\-ci.org/warner/python\-versioneer\fP)
.sp
This is a tool for managing a recorded version number in distutils\-based
python projects. The goal is to remove the tedious and error\-prone "update
the embedded version string" step from your release process. Making a new
release should be as easy as recording a new tag in your version\-control
system, and maybe making new tarballs.
.sp
## Quick Install
.INDENT 0.0
.IP \(bu 2
\fIpip install versioneer\fP to somewhere to your $PATH
.IP \(bu 2
add a \fI[versioneer]\fP section to your setup.cfg (see below)
.IP \(bu 2
run \fIversioneer install\fP in your source tree, commit the results
.UNINDENT
.sp
## Version Identifiers
.sp
Source trees come from a variety of places:
.INDENT 0.0
.IP \(bu 2
a version\-control system checkout (mostly used by developers)
.IP \(bu 2
a nightly tarball, produced by build automation
.IP \(bu 2
a snapshot tarball, produced by a web\-based VCS browser, like github\(aqs
"tarball from tag" feature
.IP \(bu 2
a release tarball, produced by "setup.py sdist", distributed through PyPI
.UNINDENT
.sp
Within each source tree, the version identifier (either a string or a number,
this tool is format\-agnostic) can come from a variety of places:
.INDENT 0.0
.IP \(bu 2
ask the VCS tool itself, e.g. "git describe" (for checkouts), which knows
about recent "tags" and an absolute revision\-id
.IP \(bu 2
the name of the directory into which the tarball was unpacked
.IP \(bu 2
an expanded VCS keyword ($Id$, etc)
.IP \(bu 2
a \fI_version.py\fP created by some earlier build step
.UNINDENT
.sp
For released software, the version identifier is closely related to a VCS
tag. Some projects use tag names that include more than just the version
string (e.g. "myproject\-1.2" instead of just "1.2"), in which case the tool
needs to strip the tag prefix to extract the version identifier. For
unreleased software (between tags), the version identifier should provide
enough information to help developers recreate the same tree, while also
giving them an idea of roughly how old the tree is (after version 1.2, before
version 1.3). Many VCS systems can report a description that captures this,
for example \fIgit describe \-\-tags \-\-dirty \-\-always\fP reports things like
"0.7\-1\-g574ab98\-dirty" to indicate that the checkout is one revision past the
0.7 tag, has a unique revision id of "574ab98", and is "dirty" (it has
uncommitted changes.
.sp
The version identifier is used for multiple purposes:
.INDENT 0.0
.IP \(bu 2
to allow the module to self\-identify its version: \fImyproject.__version__\fP
.IP \(bu 2
to choose a name and prefix for a \(aqsetup.py sdist\(aq tarball
.UNINDENT
.sp
## Theory of Operation
.sp
Versioneer works by adding a special \fI_version.py\fP file into your source
tree, where your \fI__init__.py\fP can import it. This \fI_version.py\fP knows how to
dynamically ask the VCS tool for version information at import time.
.sp
\fI_version.py\fP also contains \fI$Revision$\fP markers, and the installation
process marks \fI_version.py\fP to have this marker rewritten with a tag name
during the \fIgit archive\fP command. As a result, generated tarballs will
contain enough information to get the proper version.
.sp
To allow \fIsetup.py\fP to compute a version too, a \fIversioneer.py\fP is added to
the top level of your source tree, next to \fIsetup.py\fP and the \fIsetup.cfg\fP
that configures it. This overrides several distutils/setuptools commands to
compute the version when invoked, and changes \fIsetup.py build\fP and \fIsetup.py
sdist\fP to replace \fI_version.py\fP with a small static file that contains just
the generated version data.
.sp
## Installation
.sp
See [INSTALL.md](./INSTALL.md) for detailed installation instructions.
.sp
## Version\-String Flavors
.sp
Code which uses Versioneer can learn about its version string at runtime by
importing \fI_version\fP from your main \fI__init__.py\fP file and running the
\fIget_versions()\fP function. From the "outside" (e.g. in \fIsetup.py\fP), you can
import the top\-level \fIversioneer.py\fP and run \fIget_versions()\fP\&.
.sp
Both functions return a dictionary with different flavors of version
information:
.INDENT 0.0
.IP \(bu 2
\fI[\(aqversion\(aq]\fP: A condensed version string, rendered using the selected
style. This is the most commonly used value for the project\(aqs version
string. The default "pep440" style yields strings like \fI0.11\fP,
\fI0.11+2.g1076c97\fP, or \fI0.11+2.g1076c97.dirty\fP\&. See the "Styles" section
below for alternative styles.
.IP \(bu 2
\fI[\(aqfull\-revisionid\(aq]\fP: detailed revision identifier. For Git, this is the
full SHA1 commit id, e.g. "1076c978a8d3cfc70f408fe5974aa6c092c949ac".
.IP \(bu 2
\fI[\(aqdate\(aq]\fP: Date and time of the latest \fIHEAD\fP commit. For Git, it is the
commit date in ISO 8601 format. This will be None if the date is not
available.
.IP \(bu 2
\fI[\(aqdirty\(aq]\fP: a boolean, True if the tree has uncommitted changes. Note that
this is only accurate if run in a VCS checkout, otherwise it is likely to
be False or None
.IP \(bu 2
\fI[\(aqerror\(aq]\fP: if the version string could not be computed, this will be set
to a string describing the problem, otherwise it will be None. It may be
useful to throw an exception in setup.py if this is set, to avoid e.g.
creating tarballs with a version string of "unknown".
.UNINDENT
.sp
Some variants are more useful than others. Including \fIfull\-revisionid\fP in a
bug report should allow developers to reconstruct the exact code being tested
(or indicate the presence of local changes that should be shared with the
developers). \fIversion\fP is suitable for display in an "about" box or a CLI
\fI\-\-version\fP output: it can be easily compared against release notes and lists
of bugs fixed in various releases.
.sp
The installer adds the following text to your \fI__init__.py\fP to place a basic
version in \fIYOURPROJECT.__version__\fP:
.INDENT 0.0
.INDENT 3.5
from ._version import get_versions
__version__ = get_versions()[\(aqversion\(aq]
del get_versions
.UNINDENT
.UNINDENT
.sp
## Styles
.sp
The setup.cfg \fIstyle=\fP configuration controls how the VCS information is
rendered into a version string.
.sp
The default style, "pep440", produces a PEP440\-compliant string, equal to the
un\-prefixed tag name for actual releases, and containing an additional "local
version" section with more detail for in\-between builds. For Git, this is
TAG[+DISTANCE.gHEX[.dirty]] , using information from \fIgit describe \-\-tags
\-\-dirty \-\-always\fP\&. For example "0.11+2.g1076c97.dirty" indicates that the
tree is like the "1076c97" commit but has uncommitted changes (".dirty"), and
that this commit is two revisions ("+2") beyond the "0.11" tag. For released
software (exactly equal to a known tag), the identifier will only contain the
stripped tag, e.g. "0.11".
.sp
Other styles are available. See details.md in the Versioneer source tree for
descriptions.
.sp
## Debugging
.sp
Versioneer tries to avoid fatal errors: if something goes wrong, it will tend
to return a version of "0+unknown". To investigate the problem, run \fIsetup.py
version\fP, which will run the version\-lookup code in a verbose mode, and will
display the full contents of \fIget_versions()\fP (including the \fIerror\fP string,
which may help identify what went wrong).
.sp
## Known Limitations
.sp
Some situations are known to cause problems for Versioneer. This details the
most significant ones. More can be found on Github
[issues page](\fI\%https://github.com/warner/python\-versioneer/issues\fP).
.sp
### Subprojects
.sp
Versioneer has limited support for source trees in which \fIsetup.py\fP is not in
the root directory (e.g. \fIsetup.py\fP and \fI\&.git/\fP are \fInot\fP siblings). The are
two common reasons why \fIsetup.py\fP might not be in the root:
.INDENT 0.0
.IP \(bu 2
Source trees which contain multiple subprojects, such as
[Buildbot](\fI\%https://github.com/buildbot/buildbot\fP), which contains both
"master" and "slave" subprojects, each with their own \fIsetup.py\fP,
\fIsetup.cfg\fP, and \fItox.ini\fP\&. Projects like these produce multiple PyPI
distributions (and upload multiple independently\-installable tarballs).
.IP \(bu 2
Source trees whose main purpose is to contain a C library, but which also
provide bindings to Python (and perhaps other langauges) in subdirectories.
.UNINDENT
.sp
Versioneer will look for \fI\&.git\fP in parent directories, and most operations
should get the right version string. However \fIpip\fP and \fIsetuptools\fP have bugs
and implementation details which frequently cause \fIpip install .\fP from a
subproject directory to fail to find a correct version string (so it usually
defaults to \fI0+unknown\fP).
.sp
\fIpip install \-\-editable .\fP should work correctly. \fIsetup.py install\fP might
work too.
.sp
Pip\-8.1.1 is known to have this problem, but hopefully it will get fixed in
some later version.
.sp
[Bug #38](\fI\%https://github.com/warner/python\-versioneer/issues/38\fP) is tracking
this issue. The discussion in
[PR #61](\fI\%https://github.com/warner/python\-versioneer/pull/61\fP) describes the
issue from the Versioneer side in more detail.
[pip PR#3176](\fI\%https://github.com/pypa/pip/pull/3176\fP) and
[pip PR#3615](\fI\%https://github.com/pypa/pip/pull/3615\fP) contain work to improve
pip to let Versioneer work correctly.
.sp
Versioneer\-0.16 and earlier only looked for a \fI\&.git\fP directory next to the
\fIsetup.cfg\fP, so subprojects were completely unsupported with those releases.
.sp
### Editable installs with setuptools <= 18.5
.sp
\fIsetup.py develop\fP and \fIpip install \-\-editable .\fP allow you to install a
project into a virtualenv once, then continue editing the source code (and
test) without re\-installing after every change.
.sp
"Entry\-point scripts" (\fIsetup(entry_points={"console_scripts": ..})\fP) are a
convenient way to specify executable scripts that should be installed along
with the python package.
.sp
These both work as expected when using modern setuptools. When using
setuptools\-18.5 or earlier, however, certain operations will cause
\fIpkg_resources.DistributionNotFound\fP errors when running the entrypoint
script, which must be resolved by re\-installing the package. This happens
when the install happens with one version, then the egg_info data is
regenerated while a different version is checked out. Many setup.py commands
cause egg_info to be rebuilt (including \fIsdist\fP, \fIwheel\fP, and installing into
a different virtualenv), so this can be surprising.
.sp
[Bug #83](\fI\%https://github.com/warner/python\-versioneer/issues/83\fP) describes
this one, but upgrading to a newer version of setuptools should probably
resolve it.
.sp
### Unicode version strings
.sp
While Versioneer works (and is continually tested) with both Python 2 and
Python 3, it is not entirely consistent with bytes\-vs\-unicode distinctions.
Newer releases probably generate unicode version strings on py2. It\(aqs not
clear that this is wrong, but it may be surprising for applications when then
write these strings to a network connection or include them in bytes\-oriented
APIs like cryptographic checksums.
.sp
[Bug #71](\fI\%https://github.com/warner/python\-versioneer/issues/71\fP) investigates
this question.
.sp
## Updating Versioneer
.sp
To upgrade your project to a new release of Versioneer, do the following:
.INDENT 0.0
.IP \(bu 2
install the new Versioneer (\fIpip install \-U versioneer\fP or equivalent)
.IP \(bu 2
edit \fIsetup.cfg\fP, if necessary, to include any new configuration settings
indicated by the release notes. See [UPGRADING](./UPGRADING.md) for details.
.IP \(bu 2
re\-run \fIversioneer install\fP in your source tree, to replace
\fISRC/_version.py\fP
.IP \(bu 2
commit any changed files
.UNINDENT
.sp
## Future Directions
.sp
This tool is designed to make it easily extended to other version\-control
systems: all VCS\-specific components are in separate directories like
src/git/ . The top\-level \fIversioneer.py\fP script is assembled from these
components by running make\-versioneer.py . In the future, make\-versioneer.py
will take a VCS name as an argument, and will construct a version of
\fIversioneer.py\fP that is specific to the given VCS. It might also take the
configuration arguments that are currently provided manually during
installation by editing setup.py . Alternatively, it might go the other
direction and include code from all supported VCS systems, reducing the
number of intermediate scripts.
.sp
## License
.sp
To make Versioneer easier to embed, all its code is dedicated to the public
domain. The \fI_version.py\fP that it creates is also in the public domain.
Specifically, both are released under the Creative Commons "Public Domain
Dedication" license (CC0\-1.0), as described in
\fI\%https://creativecommons.org/publicdomain/zero/1.0/\fP .
.INDENT 0.0
.TP
.B exception versioneer.NotThisMethod
Bases: \fI\%Exception\fP
.sp
Exception raised if a method is not valid for the current scenario.
.UNINDENT
.INDENT 0.0
.TP
.B exception versioneer.VersioneerBadRootError
Bases: \fI\%Exception\fP
.sp
The project root directory is unknown or missing key files.
.UNINDENT
.INDENT 0.0
.TP
.B class versioneer.VersioneerConfig
Bases: \fI\%object\fP
.sp
Container for Versioneer configuration parameters.
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.do_setup()
Main VCS\-independent setup function for installing Versioneer.
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.do_vcs_install(manifest_in, versionfile_source, ipy)
Git\-specific installation logic for Versioneer.
.sp
For Git, this means creating/changing .gitattributes to mark _version.py
for export\-subst keyword substitution.
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.get_cmdclass()
Get the custom setuptools/distutils subclasses used by Versioneer.
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.get_config_from_root(root)
Read the project setup.cfg file to determine Versioneer config.
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.get_root()
Get the project root directory.
.sp
We require that all commands are run from the project root, i.e. the
directory that contains setup.py, setup.cfg, and versioneer.py .
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.get_version()
Get the short version string for this project.
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.get_versions(verbose=False)
Get the project version from whatever source is available.
.sp
Returns dict with two keys: \(aqversion\(aq and \(aqfull\(aq.
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.git_get_keywords(versionfile_abs)
Extract version information from the given file.
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.git_pieces_from_vcs(tag_prefix, root, verbose, run_command=<function run_command>)
Get version from \(aqgit describe\(aq in the root of the source tree.
.sp
This only gets called if the git\-archive \(aqsubst\(aq keywords were \fInot\fP
expanded, and _version.py hasn\(aqt already been rewritten with a short
version string, meaning we\(aqre inside a checked out source tree.
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.git_versions_from_keywords(keywords, tag_prefix, verbose)
Get version information from git keywords.
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.plus_or_dot(pieces)
Return a + if we don\(aqt already have one, else return a .
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.register_vcs_handler(vcs, method)
Decorator to mark a method as the handler for a particular VCS.
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.render(pieces, style)
Render the given version pieces into the requested style.
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.render_git_describe(pieces)
TAG[\-DISTANCE\-gHEX][\-dirty].
.sp
Like \(aqgit describe \-\-tags \-\-dirty \-\-always\(aq.
.sp
Exceptions:
1: no tags. HEX[\-dirty]  (note: no \(aqg\(aq prefix)
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.render_git_describe_long(pieces)
TAG\-DISTANCE\-gHEX[\-dirty].
.sp
Like \(aqgit describe \-\-tags \-\-dirty \-\-always \-long\(aq.
The distance/hash is unconditional.
.sp
Exceptions:
1: no tags. HEX[\-dirty]  (note: no \(aqg\(aq prefix)
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.render_pep440(pieces)
Build up version string, with post\-release "local version identifier".
.sp
Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you
get a tagged build and then dirty it, you\(aqll get TAG+0.gHEX.dirty
.sp
Exceptions:
1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.render_pep440_old(pieces)
TAG[.postDISTANCE[.dev0]] .
.sp
The ".dev0" means dirty.
.sp
Eexceptions:
1: no tags. 0.postDISTANCE[.dev0]
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.render_pep440_post(pieces)
TAG[.postDISTANCE[.dev0]+gHEX] .
.sp
The ".dev0" means dirty. Note that .dev0 sorts backwards
(a dirty tree will appear "older" than the corresponding clean one),
but you shouldn\(aqt be releasing software with \-dirty anyways.
.sp
Exceptions:
1: no tags. 0.postDISTANCE[.dev0]
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.render_pep440_pre(pieces)
TAG[.post.devDISTANCE] \-\- No \-dirty.
.sp
Exceptions:
1: no tags. 0.post.devDISTANCE
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None)
Call the given command(s).
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.scan_setup_py()
Validate the contents of setup.py against Versioneer\(aqs expectations.
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.versions_from_file(filename)
Try to determine the version from _version.py if present.
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.versions_from_parentdir(parentdir_prefix, root, verbose)
Try to determine the version from the parent directory name.
.sp
Source tarballs conventionally unpack into a directory that includes both
the project name and a version string. We will also support searching up
two directory levels for an appropriately named parent directory
.UNINDENT
.INDENT 0.0
.TP
.B versioneer.write_to_version_file(filename, versions)
Write the given version number to the given _version.py file.
.UNINDENT
.SH INDICES AND TABLES
.INDENT 0.0
.IP \(bu 2
genindex
.IP \(bu 2
modindex
.IP \(bu 2
search
.UNINDENT
.SH COPYRIGHT
2016, Fei Zhan
.\" Generated by docutils manpage writer.
.
